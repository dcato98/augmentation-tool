{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Augmentations Tool\n",
    "Based on this article: https://platform.ai/blog/page/2/finding-useful-augmentations-with-minimal-use-of-compute/\n",
    "\n",
    "Documentation is written assuming you've read this article and you have a classification problem.\n",
    "\n",
    "For other types of problems, it would likely be straightforward to modify the code - in particular, attention should be paid to the section titled 'Validate TTA Error Rates', where you will likely need to change the metric.\n",
    "\n",
    "**For every bold step with a number by it, you probably need to do something. If there's no number, you only need to read if you want to understand what's going on.**\n",
    "\n",
    "Note that the method implemented in this notebook has given some good results in practice, but, as mentioned in the article, has not been tested enough to determine whether these results are due to chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Path to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/dc/.fastai/data/imagewoof-160')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_path(woof, size):\n",
    "    if   size<=128: path = URLs.IMAGEWOOF_160 if woof else URLs.IMAGENETTE_160\n",
    "    elif size<=224: path = URLs.IMAGEWOOF_320 if woof else URLs.IMAGENETTE_320\n",
    "    else          : path = URLs.IMAGEWOOF     if woof else URLs.IMAGENETTE\n",
    "    return untar_data(path)\n",
    "\n",
    "woof = True\n",
    "size = 128\n",
    "\n",
    "path = get_path(woof=woof, size=size); path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define `get_data`\n",
    "\n",
    "It should accept a list of transforms (in the style of `get_transforms()`) and return a databunch.\n",
    "\n",
    "It should also create the same validation set every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(path, size, bs=64, tfms=None, workers=None):\n",
    "    if workers is None: workers = min(8, num_cpus())\n",
    "    return (ImageList.from_folder(path)\n",
    "            .split_by_rand_pct(.2, seed=42)\n",
    "            .label_from_folder()\n",
    "            .transform(tfms, size=size)\n",
    "            .databunch(bs=bs, num_workers=workers)\n",
    "            .presize(size, scale=(0.35,1))\n",
    "            .normalize(imagenet_stats))\n",
    "\n",
    "# just add transforms!\n",
    "get_data = partial(make_data, path, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define `get_learner`\n",
    "\n",
    "Define a function to make a learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(data, pretrained=True, load_fn=None, model_fn='modelbest', csv_fn='history'):\n",
    "    callback_fns = [partial(SaveModelCallback, name=model_fn),\n",
    "                    partial(CSVLogger, filename=csv_fn)]\n",
    "    learn = cnn_learner(data, models.resnet34, metrics=error_rate, pretrained=pretrained, \n",
    "                        callback_fns=callback_fns)\n",
    "    if load_fn: learn = learn.load(load_fn)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Transforms\n",
    "\n",
    "Define which transforms to test using `tfm_dict`.\n",
    "\n",
    "The following code block will define the same transforms as mentioned in the article.\n",
    "\n",
    "This method of creating tests is flexible, but rather complicated. For simple tests, it may be easier to write your own code that generates similarly structured output. In the end, `make_tfms` is just creating lists of transforms organized by transform type. If it's not apparent how you should modify `tfm_dict` to define the tests you want to perform, try running this cell as is, then inspecting the output of `make_tfms`. \n",
    "\n",
    "`make_tfms` is later used in the section titled 'Validate TTA Error Rates'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip: \n",
      "  1.  TfmPixel (flip_lr): <no params>\n",
      "  2.  TfmAffine (dihedral_affine): <no params>\n",
      "symmetric_warp: \n",
      "  3.  TfmCoord (symmetric_warp):  {'magnitude': (-0.1, 0.1)}\n",
      "  4.  TfmCoord (symmetric_warp):  {'magnitude': (-0.2, 0.2)}\n",
      "  5.  TfmCoord (symmetric_warp):  {'magnitude': (-0.3, 0.3)}\n",
      "  6.  TfmCoord (symmetric_warp):  {'magnitude': (-0.4, 0.4)}\n",
      "rotate: \n",
      "  7.  TfmAffine (rotate):  {'degrees': (-10.0, 10.0)}\n",
      "  8.  TfmAffine (rotate):  {'degrees': (-20.0, 20.0)}\n",
      "  9.  TfmAffine (rotate):  {'degrees': (-30.0, 30.0)}\n",
      "  10.  TfmAffine (rotate):  {'degrees': (-40.0, 40.0)}\n",
      "zoom: \n",
      "  11.  TfmAffine (zoom):  {'scale': (1.0, 1.1)}\n",
      "  12.  TfmAffine (zoom):  {'scale': (1.0, 1.2)}\n",
      "  13.  TfmAffine (zoom):  {'scale': (1.0, 1.3)}\n",
      "  14.  TfmAffine (zoom):  {'scale': (1.0, 1.4)}\n",
      "brightness: \n",
      "  15.  TfmLighting (brightness):  {'change': (0.45, 0.55)}\n",
      "  16.  TfmLighting (brightness):  {'change': (0.4, 0.6)}\n",
      "  17.  TfmLighting (brightness):  {'change': (0.35, 0.65)}\n",
      "  18.  TfmLighting (brightness):  {'change': (0.3, 0.7)}\n",
      "contrast: \n",
      "  19.  TfmLighting (contrast):  {'scale': (0.9, 1.1111111111111112)}\n",
      "  20.  TfmLighting (contrast):  {'scale': (0.8, 1.25)}\n",
      "  21.  TfmLighting (contrast):  {'scale': (0.7, 1.4285714285714286)}\n",
      "  22.  TfmLighting (contrast):  {'scale': (0.6, 1.6666666666666667)}\n",
      "skew: \n",
      "  23.  TfmCoord (skew):  {'direction': (0, 0), 'magnitude': 0.2}\n",
      "  24.  TfmCoord (skew):  {'direction': (0, 0), 'magnitude': 0.4}\n",
      "  25.  TfmCoord (skew):  {'direction': (0, 0), 'magnitude': 0.6}\n",
      "  26.  TfmCoord (skew):  {'direction': (0, 0), 'magnitude': 0.8}\n",
      "  27.  TfmCoord (skew):  {'direction': (7, 7), 'magnitude': 0.2}\n",
      "  28.  TfmCoord (skew):  {'direction': (7, 7), 'magnitude': 0.4}\n",
      "  29.  TfmCoord (skew):  {'direction': (7, 7), 'magnitude': 0.6}\n",
      "  30.  TfmCoord (skew):  {'direction': (7, 7), 'magnitude': 0.8}\n",
      "squish: \n",
      "  31.  TfmAffine (squish):  {'scale': (0.8333333333333334, 1.2)}\n",
      "  32.  TfmAffine (squish):  {'scale': (0.5555555555555556, 1.8)}\n",
      "  33.  TfmAffine (squish):  {'scale': (0.4166666666666667, 2.4)}\n",
      "  34.  TfmAffine (squish):  {'scale': (0.3333333333333333, 3.0)}\n",
      "rand_pad_crop: \n",
      "  35.  functools.partial(<function rand_pad at 0x7f94ae5e8050>, size=128):  {'padding': 8.0}\n",
      "  36.  functools.partial(<function rand_pad at 0x7f94ae5e8050>, size=128):  {'padding': 16.0}\n",
      "  37.  functools.partial(<function rand_pad at 0x7f94ae5e8050>, size=128):  {'padding': 32.0}\n"
     ]
    }
   ],
   "source": [
    "# For each key in `tfm_dict`, this code block will produce all combinations\n",
    "#    of aug_func(s) and parameter values\n",
    "\n",
    "### Structure of `tfm_dict`\n",
    "###\n",
    "#   {'printable_tfm_name': \n",
    "#         [aug_func or [aug_funcs],\n",
    "#          {'parameter_name1': [parameter1 values],\n",
    "#           'parameter_name2': [parameter2 values]}\n",
    "#         ]},\n",
    "#    'next_tfm': ...\n",
    "#   }\n",
    "###\n",
    "\n",
    "### For convenience, here's the transforms defined in fastai:\n",
    "\n",
    "# all_tfms = ['brightness', 'contrast', 'crop', 'crop_pad', 'cutout', 'dihedral', \n",
    "#             'dihedral_affine', 'flip_affine', 'flip_lr', 'get_transforms', 'jitter', \n",
    "#             'pad', 'perspective_warp', 'rand_pad', 'rand_crop', 'rand_zoom', \n",
    "#             'rgb_randomize', 'rotate', 'skew', 'squish', 'rand_resize_crop', \n",
    "#             'symmetric_warp', 'tilt', 'zoom', 'zoom_crop']\n",
    "\n",
    "tfm_dict = {'flip': [[flip_lr, dihedral_affine], {}], \n",
    "            'symmetric_warp': [symmetric_warp, \n",
    "                               {'magnitude': [(-m, m) for m in [.1, .2, .3, .4]]}], \n",
    "            'rotate': [rotate, \n",
    "                       {'degrees': [(-m, m) for m in [10., 20., 30., 40.]]}],\n",
    "            'zoom': [zoom, \n",
    "                     {'scale': [(1., max_zoom) for max_zoom in [1.1, 1.2, 1.3, 1.4]]}], \n",
    "            'brightness': [brightness, \n",
    "                           {'change': [(.5*(1-max_lighting), .5*(1+max_lighting))\n",
    "                                       for max_lighting in [.1, .2, .3, .4]]}], \n",
    "            'contrast': [contrast, \n",
    "                         {'scale': [(1-max_lighting, 1/(1-max_lighting))\n",
    "                                    for max_lighting in [.1, .2, .3, .4]]}],\n",
    "            'skew': [skew, \n",
    "                     {'direction': [(0, 0),(7, 7)], \n",
    "                      'magnitude': [max_skew for max_skew in [.2, .4, .6, .8]]}],\n",
    "            'squish': [squish, \n",
    "                       {'scale': [(1/max_scale, max_scale) \n",
    "                                  for max_scale in [1.2, 1.8, 2.4, 3.]]}],\n",
    "            'rand_pad_crop': [partial(rand_pad, size=size), \n",
    "                         {'padding': [size/16, size/8, size/4]}]}\n",
    "\n",
    "def generate_param_dict(names, values):\n",
    "    \"\"\"\n",
    "    Returns a list of parameter dictionaries for all combinations of parameter values.\n",
    "    \n",
    "    Parameters:\n",
    "      names  - list of parameter names           (e.g. ['direction', 'magnitude'] )\n",
    "      values - list of values for each parameter (e.g. [[(0,0),(7,7)],  [.2, .4, .6, .8]] )\n",
    "    \"\"\"\n",
    "    grid_shape = [range(len(lst)) for lst in values]\n",
    "    grid = np.array(np.meshgrid(*grid_shape)).T.reshape(-1,len(names))\n",
    "    combinations_d = [{names[n_ix]: values[n_ix][v_ix] for n_ix, v_ix in enumerate(v_ix)}\n",
    "                      for v_ix in grid]\n",
    "    return combinations_d\n",
    "\n",
    "def make_tfms(tfm_dict, pretty_print=False):\n",
    "    i = 0\n",
    "    tfms = defaultdict(list)\n",
    "    for name, tfm_info in tfm_dict.items():\n",
    "        if pretty_print: print(f'{name}: ')\n",
    "        sub_tfms = listify(tfm_info[0])\n",
    "        params = tfm_info[1]\n",
    "        for sub_tfm in sub_tfms:\n",
    "            if len(params) == 0:\n",
    "                i += 1\n",
    "                if pretty_print: print(f'  {i}.  {sub_tfm}: <no params>')\n",
    "                tfms[name].append([sub_tfm, {}])\n",
    "            else:\n",
    "                param_names = [k for k in params.keys()]\n",
    "                param_values = [params[n] for n in param_names]\n",
    "                value_combos = generate_param_dict(param_names, param_values)\n",
    "                for combo in value_combos:\n",
    "                    i += 1\n",
    "                    if pretty_print: print(f'  {i}.  {sub_tfm}:  {combo}')\n",
    "                    tfms[name].append([sub_tfm, combo])\n",
    "    return dict(tfms)\n",
    "\n",
    "make_tfms(tfm_dict, pretty_print=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a few helper functions:\n",
    "\n",
    "Feel free to skip over this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate_of_best_valid_loss(path, fn):\n",
    "    \"\"\"Returns the error_rate for the minimum validation loss.\"\"\"\n",
    "    end = '' if fn.endswith('.csv') else '.csv'\n",
    "    df = pd.read_csv(path/f'{fn}{end}')\n",
    "    idx = df.valid_loss.idxmin()\n",
    "    return df.iloc[idx].error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tta_only_w_tfms(learn:Learner, tfms:list, ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None) -> Iterator[List[Tensor]]:\n",
    "    \"\"\"\n",
    "    Computes the outputs for several augmented inputs for TTA.\n",
    "    Compare to `_tta_only` in fastai/vision/tta.py\n",
    "    \"\"\"\n",
    "    from fastai.basic_train import _loss_func2activ\n",
    "    from fastai.basic_data import DatasetType\n",
    "    \n",
    "    dl = learn.dl(ds_type)\n",
    "    ds = dl.dataset\n",
    "    old = ds.tfms\n",
    "    activ = ifnone(activ, _loss_func2activ(learn.loss_func))\n",
    "    try:\n",
    "        pbar = master_bar(range(8))\n",
    "        for i in pbar:\n",
    "            tfm = ifnone(tfms, [])\n",
    "            ds.tfms = tfm\n",
    "            yield get_preds(learn.model, dl, pbar=pbar, activ=activ)[0]\n",
    "    finally: ds.tfms = old\n",
    "        \n",
    "def _TTA_w_tfms(learn:Learner, tfms:list, beta:float=0.4, ds_type:DatasetType=DatasetType.Valid, activ:nn.Module=None) -> Tensors:\n",
    "    \"\"\"\n",
    "    Applies TTA to predict on `ds_type` dataset.\n",
    "    Compare to `_TTA` in fastai/vision/tta.py\n",
    "    \"\"\"\n",
    "    preds,y = learn.get_preds(ds_type, activ=activ)\n",
    "    all_preds = list(_tta_only_w_tfms(learn, tfms, ds_type=ds_type, activ=activ))\n",
    "    avg_preds = torch.stack(all_preds).mean(0)\n",
    "    if beta is None: return preds,avg_preds,y\n",
    "    else:\n",
    "        final_preds = preds*beta + avg_preds*(1-beta)\n",
    "        return final_preds, y\n",
    "\n",
    "# Monkey-patch Learner\n",
    "Learner.TTA_with_tfms = _TTA_w_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, learn_func, epochs_head, epochs_full, \n",
    "          lr_head=3e-3, lr_full=slice(3e-5, 3e-4),\n",
    "          model_fn='modelbest', csv_fn='history'):\n",
    "    learn = learn_func(data, model_fn=f'{model_fn}_head', csv_fn=f'{csv_fn}_head')\n",
    "    if epochs_head:\n",
    "        learn.freeze()\n",
    "        learn.fit_one_cycle(epochs_head, lr_head)\n",
    "    if epochs_full:\n",
    "        learn = learn_func(data, model_fn=f'{model_fn}_full', csv_fn=f'{csv_fn}_full')\n",
    "        learn.load(f'{model_fn}_head')\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(epochs_full, lr_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Test Hyperparameters\n",
    "\n",
    "The article doesn't mention what values were used for these. You will likely get better results by adjusting these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_HEAD = 3         # Number of epochs to train the model head\n",
    "EPOCHS_FULL = 5         # Number of epochs to train the full model\n",
    "THRESHOLD = 0.99        # Exclude transforms which don't produce an error rate less than THRESHOLD*ERR_NONE\n",
    "BETA = 0.4              # called WEIGHT_UNTRANSFORMED in the article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune with No Data Augmentation\n",
    "\n",
    "Train the last layer group on 80% of the training set for EPOCHS_HEAD epochs, without any data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.850775</td>\n",
       "      <td>0.449070</td>\n",
       "      <td>0.145174</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.568087</td>\n",
       "      <td>0.331373</td>\n",
       "      <td>0.109266</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.419854</td>\n",
       "      <td>0.305615</td>\n",
       "      <td>0.102703</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.44907015562057495.\n",
      "Better model found at epoch 1 with valid_loss value: 0.33137258887290955.\n",
      "Better model found at epoch 2 with valid_loss value: 0.30561521649360657.\n"
     ]
    }
   ],
   "source": [
    "data = get_data()\n",
    "csv_fn = 'history_no_aug'\n",
    "model_fn = 'no_aug'\n",
    "train(data, get_learner, EPOCHS_HEAD, 0, model_fn=model_fn, csv_fn=csv_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Error Rate\n",
    "\n",
    "Calculate the error rate ERR_NONE on the remaining 20% of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.102703"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERR_NONE = error_rate_of_best_valid_loss(data.path, f'{csv_fn}_head'); ERR_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate TTA Error Rates for Augmentation Tests\n",
    "\n",
    "For each kind of transformation, for each possible magnitude, calculate the TTA error rate on the remaining 20% of the training set. TTA predictions are based on `BETA*logits_without_tfms + (1 - BETA)*avg_tta_logits`.\n",
    "\n",
    "**Note: running this cell may take a while, depending on how many TTA tests there are to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_tests = make_tfms(tfm_dict)\n",
    "results = {}\n",
    "learn = get_learner(data, load_fn=f'{model_fn}_head')\n",
    "for name, tests in all_tests.items():\n",
    "    tfms = [tfm(**params) for tfm, params in tests]\n",
    "    errs = [error_rate(*learn.TTA_with_tfms(tfm, beta=BETA)) for tfm in tfms]\n",
    "    results[name] = list(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flip': [tensor(0.0892), tensor(0.0927)],\n",
       " 'symmetric_warp': [tensor(0.0892),\n",
       "  tensor(0.0861),\n",
       "  tensor(0.0876),\n",
       "  tensor(0.0838)],\n",
       " 'rotate': [tensor(0.0931), tensor(0.0911), tensor(0.0876), tensor(0.0884)],\n",
       " 'zoom': [tensor(0.0923), tensor(0.0876), tensor(0.0838), tensor(0.0838)],\n",
       " 'brightness': [tensor(0.1019),\n",
       "  tensor(0.1039),\n",
       "  tensor(0.1012),\n",
       "  tensor(0.1015)],\n",
       " 'contrast': [tensor(0.1019), tensor(0.1019), tensor(0.1019), tensor(0.0996)],\n",
       " 'skew': [tensor(0.0919),\n",
       "  tensor(0.0942),\n",
       "  tensor(0.0973),\n",
       "  tensor(0.0969),\n",
       "  tensor(0.0938),\n",
       "  tensor(0.0907),\n",
       "  tensor(0.0965),\n",
       "  tensor(0.0950)],\n",
       " 'squish': [tensor(0.0942), tensor(0.0896), tensor(0.0896), tensor(0.0892)],\n",
       " 'rand_pad_crop': [tensor(0.0903), tensor(0.0907), tensor(0.0919)]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick Best Transformations\n",
    "\n",
    "For each kind of transformation, choose the magnitude which leads to the lowest TTA error rate, if that error rate is lower than THRESHOLD * ERR_NONE; otherwise, don't include that kind of transformation in the final set of augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[TfmPixel (flip_lr), {}],\n",
       " [TfmCoord (symmetric_warp), {'magnitude': (-0.4, 0.4)}],\n",
       " [TfmAffine (rotate), {'degrees': (-30.0, 30.0)}],\n",
       " [TfmAffine (zoom), {'scale': (1.0, 1.3)}],\n",
       " [TfmLighting (brightness), {'change': (0.35, 0.65)}],\n",
       " [TfmLighting (contrast), {'scale': (0.6, 1.6666666666666667)}],\n",
       " [TfmCoord (skew), {'direction': (7, 7), 'magnitude': 0.4}],\n",
       " [TfmAffine (squish), {'scale': (0.3333333333333333, 3.0)}],\n",
       " [functools.partial(<function rand_pad at 0x7f94ae5e8050>, size=128),\n",
       "  {'padding': 8.0}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tfms = []\n",
    "tfm_types = list(results.keys())\n",
    "for tfm_type in tfm_types:\n",
    "    errs = results[tfm_type]\n",
    "    best_idx = np.argmin(errs)\n",
    "    best_err = errs[best_idx]\n",
    "    if best_err < THRESHOLD * ERR_NONE:\n",
    "        final_tfms.append(all_tests[tfm_type][best_idx])\n",
    "final_tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Best Transformations\n",
    "\n",
    "With the chosen set of augmentations, train the head for EPOCHS_HEAD epochs and the full network for EPOCHS_FULL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.600415</td>\n",
       "      <td>0.553326</td>\n",
       "      <td>0.184170</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.117600</td>\n",
       "      <td>0.442382</td>\n",
       "      <td>0.146718</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.963632</td>\n",
       "      <td>0.379293</td>\n",
       "      <td>0.119691</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.5533258318901062.\n",
      "Better model found at epoch 1 with valid_loss value: 0.44238224625587463.\n",
      "Better model found at epoch 2 with valid_loss value: 0.3792932331562042.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.927730</td>\n",
       "      <td>0.364375</td>\n",
       "      <td>0.120077</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.940380</td>\n",
       "      <td>0.442665</td>\n",
       "      <td>0.147490</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.869400</td>\n",
       "      <td>0.404624</td>\n",
       "      <td>0.136680</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.758800</td>\n",
       "      <td>0.355120</td>\n",
       "      <td>0.115058</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.740413</td>\n",
       "      <td>0.338701</td>\n",
       "      <td>0.109653</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.36437463760375977.\n",
      "Better model found at epoch 3 with valid_loss value: 0.3551204204559326.\n",
      "Better model found at epoch 4 with valid_loss value: 0.3387012779712677.\n"
     ]
    }
   ],
   "source": [
    "tfms = []\n",
    "for tfm_func, params in final_tfms:\n",
    "    tfm = tfm_func(**params)\n",
    "    # some tfm_funcs return a list of tfms, we need to squish them all together\n",
    "    tfms.extend(tfm if is_listy(tfm) else [tfm])\n",
    "    \n",
    "data = get_data(tfms=[tfms, []])\n",
    "csv_fn = 'history_best'\n",
    "model_fn = 'best_tfms'\n",
    "train(data, get_learner, EPOCHS_HEAD, EPOCHS_FULL, model_fn=model_fn, csv_fn=csv_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.109653"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERR_BEST_AUGS = error_rate_of_best_valid_loss(data.path, f'{csv_fn}_full')\n",
    "ERR_BEST_AUGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Baseline\n",
    "\n",
    "As a baseline, train the network for the same number of epochs using the transforms provided by get_transforms()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.914859</td>\n",
       "      <td>0.409710</td>\n",
       "      <td>0.130888</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.630220</td>\n",
       "      <td>0.338875</td>\n",
       "      <td>0.116602</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.497871</td>\n",
       "      <td>0.295071</td>\n",
       "      <td>0.096525</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.4097101092338562.\n",
      "Better model found at epoch 1 with valid_loss value: 0.3388746380805969.\n",
      "Better model found at epoch 2 with valid_loss value: 0.2950712740421295.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.501394</td>\n",
       "      <td>0.327873</td>\n",
       "      <td>0.106564</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.496799</td>\n",
       "      <td>0.340813</td>\n",
       "      <td>0.105019</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.432724</td>\n",
       "      <td>0.327442</td>\n",
       "      <td>0.105019</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.334245</td>\n",
       "      <td>0.287076</td>\n",
       "      <td>0.093050</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.275871</td>\n",
       "      <td>0.286491</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.3278730511665344.\n",
      "Better model found at epoch 2 with valid_loss value: 0.3274422883987427.\n",
      "Better model found at epoch 3 with valid_loss value: 0.28707581758499146.\n",
      "Better model found at epoch 4 with valid_loss value: 0.2864907383918762.\n"
     ]
    }
   ],
   "source": [
    "tfms = get_transforms()\n",
    "data = get_data(tfms=tfms)\n",
    "csv_fn = 'history_baseline'\n",
    "model_fn = 'baseline'\n",
    "train(data, get_learner, EPOCHS_HEAD, EPOCHS_FULL, model_fn=model_fn, csv_fn=csv_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09575299999999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERR_DEFAULT_AUGS = error_rate_of_best_valid_loss(data.path, f'{csv_fn}_full')\n",
    "ERR_DEFAULT_AUGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Train 2nd Baseline - No Augs\n",
    "\n",
    "This wasn't done in the article, but this is a good check. If you get a better result using no data augmentation at all, then you are probably not training for enough epochs as additional data augmentation can cause slower convergence (TODO: need to verify this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.828232</td>\n",
       "      <td>0.469234</td>\n",
       "      <td>0.136293</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.563967</td>\n",
       "      <td>0.351915</td>\n",
       "      <td>0.124710</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.429604</td>\n",
       "      <td>0.313480</td>\n",
       "      <td>0.099228</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.4692339599132538.\n",
      "Better model found at epoch 1 with valid_loss value: 0.35191527009010315.\n",
      "Better model found at epoch 2 with valid_loss value: 0.3134795129299164.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.412930</td>\n",
       "      <td>0.328887</td>\n",
       "      <td>0.105405</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.446553</td>\n",
       "      <td>0.347663</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.314578</td>\n",
       "      <td>0.328951</td>\n",
       "      <td>0.113514</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.229698</td>\n",
       "      <td>0.312599</td>\n",
       "      <td>0.101544</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.180178</td>\n",
       "      <td>0.307187</td>\n",
       "      <td>0.102317</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.32888707518577576.\n",
      "Better model found at epoch 3 with valid_loss value: 0.3125993311405182.\n",
      "Better model found at epoch 4 with valid_loss value: 0.30718743801116943.\n"
     ]
    }
   ],
   "source": [
    "tfms = None\n",
    "data = get_data(tfms=tfms)\n",
    "csv_fn = 'history_baseline_none'\n",
    "model_fn = 'baseline_none'\n",
    "train(data, get_learner, EPOCHS_HEAD, EPOCHS_FULL, model_fn=model_fn, csv_fn=csv_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10231699999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERR_BASELINE_NONE = error_rate_of_best_valid_loss(data.path, f'{csv_fn}_full')\n",
    "ERR_BASELINE_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_none: 0.10231699999999999 \n",
      "default_augs: 0.09575299999999999 \n",
      "best_augs: 0.109653\n"
     ]
    }
   ],
   "source": [
    "try: print('baseline_none:', ERR_BASELINE_NONE, '\\ndefault_augs:', ERR_DEFAULT_AUGS, '\\nbest_augs:', ERR_BEST_AUGS)\n",
    "except: print('default_augs:', ERR_DEFAULT_AUGS, '\\nbest_augs:', ERR_BEST_AUGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[TfmPixel (flip_lr), {}],\n",
       " [TfmCoord (symmetric_warp), {'magnitude': (-0.4, 0.4)}],\n",
       " [TfmAffine (rotate), {'degrees': (-30.0, 30.0)}],\n",
       " [TfmAffine (zoom), {'scale': (1.0, 1.3)}],\n",
       " [TfmLighting (brightness), {'change': (0.35, 0.65)}],\n",
       " [TfmLighting (contrast), {'scale': (0.6, 1.6666666666666667)}],\n",
       " [TfmCoord (skew), {'direction': (7, 7), 'magnitude': 0.4}],\n",
       " [TfmAffine (squish), {'scale': (0.3333333333333333, 3.0)}],\n",
       " [functools.partial(<function rand_pad at 0x7f94ae5e8050>, size=128),\n",
       "  {'padding': 8.0}]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([RandTransform(tfm=TfmCrop (crop_pad), kwargs={'row_pct': (0, 1), 'col_pct': (0, 1), 'padding_mode': 'reflection'}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmPixel (flip_lr), kwargs={}, p=0.5, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmCoord (symmetric_warp), kwargs={'magnitude': (-0.2, 0.2)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (rotate), kwargs={'degrees': (-10.0, 10.0)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (zoom), kwargs={'scale': (1.0, 1.1), 'row_pct': (0, 1), 'col_pct': (0, 1)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.4, 0.6)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.8, 1.25)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True)],\n",
       " [RandTransform(tfm=TfmCrop (crop_pad), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
